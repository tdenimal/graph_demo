{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601381700615",
   "display_name": "Python 3.7.9 64-bit ('graph_demo': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "176\n"
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "_20m_paper = newspaper.build('https://www.20minutes.fr/politique/', memoize_articles=False,fetch_images=False)\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "for article in _20m_paper.articles:\n",
    "   # check to see if the article url is not within the urls_set\n",
    "   if article.url not in urls_set:\n",
    "     # add the unique article url to the set\n",
    "     urls_set.add(article.url)\n",
    "     # remove all links for article commentaires\n",
    "     if not str(article.url).endswith('commentaires'):\n",
    "        papers.append(article.url)\n",
    "\n",
    "print(len(papers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "176\n"
    }
   ],
   "source": [
    "import newspaper\n",
    "import requests\n",
    "from newspaper.utils import BeautifulSoup\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "\n",
    "base_url = 'https://www.20minutes.fr/'\n",
    "\n",
    "_20m_paper = newspaper.build(base_url, \n",
    "fetch_images=False, memoize_articles=False)\n",
    "\n",
    "for article in _20m_paper.articles:\n",
    "   # check to see if the article url is not within the urls_set\n",
    "   if article.url not in urls_set:\n",
    "     # add the unique article url to the set\n",
    "     urls_set.add(article.url)\n",
    "     # remove all links for article commentaires\n",
    "     if not str(article.url).endswith('commentaires'):\n",
    "        papers.append(article.url)\n",
    "\n",
    " \n",
    "_20_urls = {'societe': base_url+'societe',\n",
    "             'politique': base_url+'politique',\n",
    "             'faits_divers': base_url+'faits_divers',\n",
    "             'monde': base_url+'monde',\n",
    "             'culture':base_url+'culture',\n",
    "             'people': base_url+'people',\n",
    "             'sports': base_url+'sports',\n",
    "             'economie': base_url+'economie',\n",
    "             'sciences': base_url+'sciences',\n",
    "             'planete': base_url+'planete',\n",
    "             'high-tech' : base_url+'high-tech',\n",
    "             }\n",
    "\n",
    "\n",
    "for category, url in _20_urls.items():\n",
    "   raw_html = requests.get(url)\n",
    "   soup = BeautifulSoup(raw_html.text, 'html.parser')\n",
    "   for articles_tags in soup.findAll('div', {'class': 'articles'}):\n",
    "      for article_href in articles_tags.find_all('a', href=True):\n",
    "         if not str(article_href['href']).endswith('commentaires'):\n",
    "           urls_set.add(article_href['href'])\n",
    "           papers.append(article_href['href'])\n",
    "\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n30\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n70\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n120\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n180\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n250\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n330\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n420\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n519\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n627\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n745\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n873\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1011\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1159\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1317\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1485\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1663\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1851\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2049\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2257\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2475\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-054608116be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mshow_more\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'//button[@type=\"button\"][contains(.,\"Voir plus\")]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arguments[0].click();\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_more\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import string\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "\n",
    "browser = webdriver.Chrome('/mnt/c/users/tdenimal/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "wait = WebDriverWait(browser, 10)\n",
    "browser.get(base_url+'societe')\n",
    "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        show_more = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@type=\"button\"][contains(.,\"Voir plus\")]')))\n",
    "        browser.execute_script(\"arguments[0].click();\", show_more)\n",
    "        print(show_more)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    \n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    for articles_tags in soup.findAll('article'):\n",
    "        for article_href in articles_tags.find_all('a', href=True):\n",
    "            if not str(article_href['href']).endswith('commentaires'):\n",
    "                urls_set.add(article_href['href'])\n",
    "                papers.append(article_href['href'])\n",
    "\n",
    "    print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'https://www.20minutes.fr/'"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ArticleException",
     "evalue": "Article `download()` failed with HTTPSConnectionPool(host='www.20minutes.fr', port=443): Max retries exceeded with url: /societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3415e1f710>: Failed to establish a new connection: [Errno -2] Name or service not known'))) on URL https://www.20minutes.fr/societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-0e932fff2065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfirst_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_demo/lib/python3.7/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_demo/lib/python3.7/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             raise ArticleException('Article `download()` failed with %s on URL %s' %\n\u001b[0;32m--> 532\u001b[0;31m                   (self.download_exception_msg, self.url))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthrow_if_not_parsed_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArticleException\u001b[0m: Article `download()` failed with HTTPSConnectionPool(host='www.20minutes.fr', port=443): Max retries exceeded with url: /societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3415e1f710>: Failed to establish a new connection: [Errno -2] Name or service not known'))) on URL https://www.20minutes.fr/societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "first_article = Article(url=base_url+papers[1][1:], language='fr')\n",
    "first_article.download()\n",
    "first_article.parse()\n",
    "first_article.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = fr_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('VILLEFONTAINE', 'ORG'), ('Grenoble', 'LOC'), ('Villefontaine', 'PER'), ('Victorine', 'LOC'), ('— A. Merlet', 'PER'), ('AFP', 'ORG'), ('Victorine', 'PER'), ('Villefontaine', 'LOC'), ('Isère', 'LOC'), ('étang de Saint-Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('Isère', 'LOC'), ('Victorine', 'LOC'), ('Vienne', 'LOC'), ('république de Grenoble', 'LOC'), ('Victorine DARTOIS', 'MISC'), ('St Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('👮', 'MISC'), (\"Gendarmerie de l'Isère\", 'ORG'), ('September', 'MISC'), ('Victorine', 'PER'), ('»', 'MISC'), ('Audrey Quey', 'PER'), ('République de Vienne', 'LOC'), ('Grenoble', 'LOC'), ('» du décès de la jeune femme', 'MISC'), ('»', 'MISC'), ('Le Dauphiné Libéré', 'MISC'), ('Saint-Hubert', 'PER'), ('Victorine', 'PER'), ('Marques', 'LOC'), ('Villefontaine', 'LOC'), ('Fougères', 'LOC'), ('Victorine', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'LOC')]\n"
    }
   ],
   "source": [
    "doc = nlp(first_article.text)\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('VILLEFONTAINE', 'ORG'), ('Grenoble', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'MISC'), ('A. Merlet', 'PER'), ('AFP', 'ORG'), ('Victorine', 'MISC'), ('Villefontaine', 'LOC'), ('Isère', 'LOC'), ('réserve naturelle de l’étang de Saint-Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('Isère', 'LOC'), ('Victorine', 'LOC'), ('Vienne', 'LOC'), ('république de Grenoble', 'LOC'), ('20 Minutes', 'MISC'), ('Victorine DARTOIS', 'PER'), ('étang de St Bonnet', 'LOC'), ('19H', 'LOC'), ('Villefontaine', 'LOC'), ('👮', 'MISC'), (\"Gendarmerie de l'Isère\", 'ORG'), ('September 28', 'MISC'), ('Victorine', 'MISC'), ('Audrey Quey', 'PER'), ('République de Vienne', 'LOC'), ('Grenoble', 'LOC'), ('Le Dauphiné Libéré', 'ORG'), ('Saint-Hubert', 'PER'), ('Victorine', 'PER'), ('Marques', 'LOC'), ('Villefontaine', 'LOC'), ('Fougères', 'LOC'), ('Victorine', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'PER')]\n"
    }
   ],
   "source": [
    "doc = nlp(first_article.text)\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}