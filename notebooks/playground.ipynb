{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601381700615",
   "display_name": "Python 3.7.9 64-bit ('graph_demo': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "176\n"
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "_20m_paper = newspaper.build('https://www.20minutes.fr/politique/', memoize_articles=False,fetch_images=False)\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "for article in _20m_paper.articles:\n",
    "   # check to see if the article url is not within the urls_set\n",
    "   if article.url not in urls_set:\n",
    "     # add the unique article url to the set\n",
    "     urls_set.add(article.url)\n",
    "     # remove all links for article commentaires\n",
    "     if not str(article.url).endswith('commentaires'):\n",
    "        papers.append(article.url)\n",
    "\n",
    "print(len(papers)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "176\n"
    }
   ],
   "source": [
    "import newspaper\n",
    "import requests\n",
    "from newspaper.utils import BeautifulSoup\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "\n",
    "base_url = 'https://www.20minutes.fr/'\n",
    "\n",
    "_20m_paper = newspaper.build(base_url, \n",
    "fetch_images=False, memoize_articles=False)\n",
    "\n",
    "for article in _20m_paper.articles:\n",
    "   # check to see if the article url is not within the urls_set\n",
    "   if article.url not in urls_set:\n",
    "     # add the unique article url to the set\n",
    "     urls_set.add(article.url)\n",
    "     # remove all links for article commentaires\n",
    "     if not str(article.url).endswith('commentaires'):\n",
    "        papers.append(article.url)\n",
    "\n",
    " \n",
    "_20_urls = {'societe': base_url+'societe',\n",
    "             'politique': base_url+'politique',\n",
    "             'faits_divers': base_url+'faits_divers',\n",
    "             'monde': base_url+'monde',\n",
    "             'culture':base_url+'culture',\n",
    "             'people': base_url+'people',\n",
    "             'sports': base_url+'sports',\n",
    "             'economie': base_url+'economie',\n",
    "             'sciences': base_url+'sciences',\n",
    "             'planete': base_url+'planete',\n",
    "             'high-tech' : base_url+'high-tech',\n",
    "             }\n",
    "\n",
    "\n",
    "for category, url in _20_urls.items():\n",
    "   raw_html = requests.get(url)\n",
    "   soup = BeautifulSoup(raw_html.text, 'html.parser')\n",
    "   for articles_tags in soup.findAll('div', {'class': 'articles'}):\n",
    "      for article_href in articles_tags.find_all('a', href=True):\n",
    "         if not str(article_href['href']).endswith('commentaires'):\n",
    "           urls_set.add(article_href['href'])\n",
    "           papers.append(article_href['href'])\n",
    "\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n30\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n70\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n120\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n180\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n250\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n330\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n420\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n519\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n627\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n745\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n873\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1011\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1159\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1317\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1485\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1663\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n1851\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2049\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2257\n<selenium.webdriver.remote.webelement.WebElement (session=\"4dfd66bd1c0371674d7606f68c80d58a\", element=\"d3af8ec8-d4f4-4d73-93cb-68ce045c5e61\")>\n2475\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-054608116be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mshow_more\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_to_be_clickable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'//button[@type=\"button\"][contains(.,\"Voir plus\")]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arguments[0].click();\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_more\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import string\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "papers = []\n",
    "urls_set = set()\n",
    "\n",
    "browser = webdriver.Chrome('/mnt/c/users/tdenimal/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "wait = WebDriverWait(browser, 10)\n",
    "browser.get(base_url+'societe')\n",
    "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        show_more = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@type=\"button\"][contains(.,\"Voir plus\")]')))\n",
    "        browser.execute_script(\"arguments[0].click();\", show_more)\n",
    "        print(show_more)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    \n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    for articles_tags in soup.findAll('article'):\n",
    "        for article_href in articles_tags.find_all('a', href=True):\n",
    "            if not str(article_href['href']).endswith('commentaires'):\n",
    "                urls_set.add(article_href['href'])\n",
    "                papers.append(article_href['href'])\n",
    "\n",
    "    print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'https://www.20minutes.fr/'"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ArticleException",
     "evalue": "Article `download()` failed with HTTPSConnectionPool(host='www.20minutes.fr', port=443): Max retries exceeded with url: /societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3415e1f710>: Failed to establish a new connection: [Errno -2] Name or service not known'))) on URL https://www.20minutes.fr/societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-0e932fff2065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfirst_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfirst_article\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_demo/lib/python3.7/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/graph_demo/lib/python3.7/site-packages/newspaper/article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mArticleDownloadState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESPONSE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             raise ArticleException('Article `download()` failed with %s on URL %s' %\n\u001b[0;32m--> 532\u001b[0;31m                   (self.download_exception_msg, self.url))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthrow_if_not_parsed_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArticleException\u001b[0m: Article `download()` failed with HTTPSConnectionPool(host='www.20minutes.fr', port=443): Max retries exceeded with url: /societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f3415e1f710>: Failed to establish a new connection: [Errno -2] Name or service not known'))) on URL https://www.20minutes.fr/societe/2872907-20200929-attaque-paris-scenario-agression-couteau-devant-charlie-hebdo-precise"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "first_article = Article(url=base_url+papers[1][1:], language='fr')\n",
    "first_article.download()\n",
    "first_article.parse()\n",
    "first_article.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fr_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = fr_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('VILLEFONTAINE', 'ORG'), ('Grenoble', 'LOC'), ('Villefontaine', 'PER'), ('Victorine', 'LOC'), ('‚Äî A. Merlet', 'PER'), ('AFP', 'ORG'), ('Victorine', 'PER'), ('Villefontaine', 'LOC'), ('Is√®re', 'LOC'), ('√©tang de Saint-Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('Is√®re', 'LOC'), ('Victorine', 'LOC'), ('Vienne', 'LOC'), ('r√©publique de Grenoble', 'LOC'), ('Victorine DARTOIS', 'MISC'), ('St Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('üëÆ', 'MISC'), (\"Gendarmerie de l'Is√®re\", 'ORG'), ('September', 'MISC'), ('Victorine', 'PER'), ('¬ª', 'MISC'), ('Audrey Quey', 'PER'), ('R√©publique de Vienne', 'LOC'), ('Grenoble', 'LOC'), ('¬ª du d√©c√®s de la jeune femme', 'MISC'), ('¬ª', 'MISC'), ('Le Dauphin√© Lib√©r√©', 'MISC'), ('Saint-Hubert', 'PER'), ('Victorine', 'PER'), ('Marques', 'LOC'), ('Villefontaine', 'LOC'), ('Foug√®res', 'LOC'), ('Victorine', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'LOC')]\n"
    }
   ],
   "source": [
    "doc = nlp(first_article.text)\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('VILLEFONTAINE', 'ORG'), ('Grenoble', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'MISC'), ('A. Merlet', 'PER'), ('AFP', 'ORG'), ('Victorine', 'MISC'), ('Villefontaine', 'LOC'), ('Is√®re', 'LOC'), ('r√©serve naturelle de l‚Äô√©tang de Saint-Bonnet', 'LOC'), ('Villefontaine', 'LOC'), ('Is√®re', 'LOC'), ('Victorine', 'LOC'), ('Vienne', 'LOC'), ('r√©publique de Grenoble', 'LOC'), ('20 Minutes', 'MISC'), ('Victorine DARTOIS', 'PER'), ('√©tang de St Bonnet', 'LOC'), ('19H', 'LOC'), ('Villefontaine', 'LOC'), ('üëÆ', 'MISC'), (\"Gendarmerie de l'Is√®re\", 'ORG'), ('September 28', 'MISC'), ('Victorine', 'MISC'), ('Audrey Quey', 'PER'), ('R√©publique de Vienne', 'LOC'), ('Grenoble', 'LOC'), ('Le Dauphin√© Lib√©r√©', 'ORG'), ('Saint-Hubert', 'PER'), ('Victorine', 'PER'), ('Marques', 'LOC'), ('Villefontaine', 'LOC'), ('Foug√®res', 'LOC'), ('Victorine', 'LOC'), ('Villefontaine', 'LOC'), ('Victorine', 'PER')]\n"
    }
   ],
   "source": [
    "doc = nlp(first_article.text)\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}